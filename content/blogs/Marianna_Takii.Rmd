---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna
  sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa
  sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem
  consequat tincidunt. Vivamus et sagittis tempus.
draft: false
image: pic07.jpg
keywords: ""
slug: marianna
title: Aliquam
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset 
library(here)
library(janitor)
```

# <b>Biography (Task 1)</b>

My name is Marianna Taki and I am 21 years old. I was born and raised in Cyprus an island in the Mediterranean. Here is an image of one of the best beaches in Cyprus: ![](https://www.visitcyprus.com/media/k2/items/cache/ca9456ad89fef6c66a71b99b32dfe05e_XL.jpg)

For the past three years I have been studying and living in the UK. I studied <i>BSc Mathematics</i> at the University of Bath. My undergraduate degree was one of the most important steps in my life as it not only taught me how to exercise critical thinking but it also introduced me to programming and data analysis. This was when I knew that this is a field that I feel passionate about and want to explore more and encouraged me to apply for the <i>Masters in Analytics and Management</i> at LBS.

Some of my favourite modules during university include:

-   Applied Statistics
-   Introduction to Econometrics
-   Optimization Methods of Operational Research

In my free time I love to cook and exercise. For the past 2 years, I have developed a passion for walking and exploring different areas of Bath and Cyprus through exercising. I have walked multiple natural trails these past few months and feel that this new hobby has allowed me not only to improve my mental and physical health but also to discover the place I live in a different way. I am excited to do the same once I move to London.

Lastly, I have been a volunteer from a very young age starting from secondary school and continuing in University. One of the most exciting projects I participated in was when volunteering for the V Team last year, the largest volunteering cohort of the University of Bath. As a Project Leader I managed to keep volunteering active during the pandemic for the entire academic year and carried out exciting projects to help our local community such as helping charities recruit new volunteers and sending out Christmas essentials to families in need.

Below you can find my Linkedin profile: <https://www.linkedin.com/in/marianna-taki/>

# <b> Task 2: `gapminder` country comparison </b>

You have seen the `gapminder` dataset that has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. To get a glimpse of the dataframe, namely to see the variable names, variable types, etc., we use the `glimpse` function. We also want to have a look at the first 20 rows of data.

```{r}
glimpse(gapminder)

head(gapminder, 20) # look at the first 20 rows of the dataframe

```

Your task is to produce two graphs of how life expectancy has changed over the years for the `country` and the `continent` you come from.

I have created the `country_data` and `continent_data` with the code below.

```{r}
country_data <- gapminder %>% 
            filter(country == "Greece") 

continent_data <- gapminder %>% 
            filter(continent == "Europe")
```

First, create a plot of life expectancy over time for the single country you chose.

```{r, lifeExp_one_country}
 plot1 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
   geom_point() +
  geom_smooth(se = FALSE)+
  NULL 

 plot1
```

Next we need to add a title.

```{r, lifeExp_one_country_with_label}
plot2 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
   geom_point() +
  geom_smooth(se = FALSE)+
  NULL +labs(title="Life expectancy in Greece over time") +
  theme(plot.title = element_text(hjust = 0.5))


plot2
```

Secondly, produce a plot for all countries in the *continent* you come from.

```{r lifeExp_one_continent}
 plot3<-ggplot(continent_data, mapping = aes(x =year  , y =lifeExp  , colour=country , group =country))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   NULL +
  labs(title="Life expectancy over time across Europe")+
  theme(plot.title = element_text(hjust = 0.5))

plot3
```

Finally, using the original `gapminder` data, produce a life expectancy over time graph, grouped (or faceted) by continent.

```{r lifeExp_facet_by_continent}
plot4<- ggplot(data = gapminder , mapping = aes(x =year  , y =lifeExp  , colour=country ))+
   geom_point() + 
   geom_smooth(se = FALSE) +
   facet_wrap(~continent) +
   theme(legend.position="none") + #remove all legends
   NULL +
  labs(title="Life expectancy over time across continents")+
  theme(plot.title = element_text(hjust = 0.5))

  
  plot4
```

## <i> Given these trends, what can you say about life expectancy since 1952? Again, don't just say what's happening in the graph. Tell some sort of story and speculate about the differences in the patterns. </i>

In 'plot1' we can see how Life expectancy in Greece has changed over time, since 1952. Life expectancy is seen to increase significantly until 1985 from about 66 years to 76 years of age, an increase of 10 years. After 1985, life expectancy continued to increase more steadily, reaching about 79 years old by 2007. Being a developed country, Greece has had an improved healthcare and education system over the years resulting to an improved life expectancy. Furthermore, standards of living have improved due to industrialization and modernization which resulted into less people working in hard physical labour jobs.

'Plot 2' looks at the patterns of life expectancy over time in European countries. It seems that the trend followed by Greece is also observed in most European countries with life expectancy increasing over the years 1952 to 2007. Some countries have seen larger rises in life expectancy with Turkey experiencing the sharpest increase from approximately 43 years of age in 1952 to 71 years of age in 2007. This large increase in Turkey is possibly due to the fact that it had been staggering to develop in comparison to other European countries and that's why it generally had much lower life expectancies over the years.

In 'Plot 3' life expectancies for all five continents are compared over time. It is obvious that there has been an increase in life expectancy over the years across all continents however the extent of this increase differs significantly for every continent. European and Oceanian countries have had higher life expectancies than other continents throughout time and have seen an increase in life expectancy ranging from about 60-70 years old in 1952 and increasing to ages of 70-80 years old by 2007. In general, most countries have seen an increase of about 10 years in Oceania and Europe. This is a result of the improvement of healthcare and education systems in the developed world.

When looking at Africa, America and Asia the spread of life expectancies is much larger across countries. In general, life expectancy seems to be lower in these three continents compared to Europe and Oceania. This signals that many of the countries in Africa, America and Asia are developing countries which haven't developed medical systems and standards of living as much as Europe and Oceania. There is a general trend of increase in life expectancy in these continents since there is some development in these countries over time. However they are still lagging in development compared to Europe and Oceania. It is important to observe that in Africa some countries seem to have experienced a fall in life expectancy at some point. This may be a result of third world countries experiencing wars or deadly illnesses. The fact that in Asia and Americas there is a big spread in life expectancy shows that there is a mix of developed and developing countries in these continents.

# <b> Task 3: Brexit vote analysis </b>

We will have a look at the results of the 2016 Brexit vote in the UK. First we read the data using `read_csv()` and have a quick glimpse at the data

```{r load_brexit_data, warning=FALSE, message=FALSE}
brexit_results <- read_csv(here::here("data","brexit_results.csv"))


glimpse(brexit_results)
```

The data comes from [Elliott Morris](https://www.thecrosstab.com/), who cleaned it and made it available through his [DataCamp class on analysing election and polling data in R](https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r).

Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies).

To get a sense of the spread, or distribution, of the data, we can plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) +
  labs(title="Histogram of % of votes in favour of Brexit",subtitle="Data from Elliott Morris",
         x="% of votes in favour of Brexit",
         y="Frequency density")+
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))


# density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
  labs(title="Density plot of % of votes in favour of Brexit",subtitle="Data from Elliott Morris",
         x="% of votes in favour of Brexit",
         y="Density")+
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))



# The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent) +
  labs(title="ECDF of % of votes in favour of Brexit",subtitle="Data from Elliott Morris",
         x="% of votes in favour of Brexit",
         y="Cumulative distribution")+
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))

  


```

One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share`. To do this, let us get the correlation between the two variables

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor() 
```

The correlation is almost 0.5, which shows that the two variables are positively correlated.

We can also create a scatterplot between these two variables using `geom_point`. We also add the best fit line, using `geom_smooth(method = "lm")`.

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method="lm" to get the best straight-line
  geom_smooth(method = "lm") + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  NULL +
  labs(title="Scatterplot between native UK voters and % of voters in favour of Brexit",subtitle="Data from Elliott Morris",
         x="Native UK voters",
         y="% of votes in favour of Brexit")+
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))

  
```

## <i> What can you say about the relationship shown above? Again, don't just say what's happening in the graph. Tell some sort of story and speculate about the differences in the patterns.</i>

The histogram and density plot show that the percentage of votes in favour of Brexit follow a left skewed distribution. We can see that the majority of the UK constituencies had about 50-60% of voters for Brexit. This observation shows that in most constituencies voters were split between Brexit which reflects the final result as the final vote was very close with the UK voting to leave the EU with 52% against 48%. The ECDF plot also captures this as we can see the curve increasing sharply between 40-60% of votes and showing that about 61% of the constituencies had leave votes within this range.

From the scatterplot above, and the positive correlation found between the native UK voters and the percentage of voters for Brexit it is indeed the case that the more native UK voters a constituency has the more Brexit voters there are. This backs up the theory that UK nationals may be in fear of immigration. The calculated correlation between these two variables is about 0.5 which can be considered as a moderately strong correlation. Of course, as expected most of the constituencies are almost entirely made up of UK nationals. This is seen by the large density of points in the right end of the graph. Observing closely these points, we can see that there is a large spread in the percentage of voters voting to leave the UK. Hence, there are mixed views across constituencies even though made up of UK nationals. From this we can speculate that UK nationality linked to fear of immigration was not the main reason behind the decision for Brexit.

# <b> Task 4: Animal rescue incidents attended by the London Fire Brigade </b>

[The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.

Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()


glimpse(animal_rescue)
```

One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)

```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

Let us try to see how many incidents we have by animal group. Again, we can do this either using group_by() and summarise(), or by using count()

```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

## <i> Do you see anything strange in these tables? </i>

There are two rows "Cat" and "cat" that represent the same animal category but due to R's sensitivity in caps they are recognized differently. We should use our knowledge for changing strings to fix this so that these two are merged into one animal group.

Finally, let us have a look at the notional cost for rescuing each of these animals. As the LFB says,

> Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

There is two things we will do:

1.  Calculate the mean and median `incident_notional_cost` for each `animal_group_parent`
2.  Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`.

Before we go on, however, we need to fix `incident_notional_cost` as it is stored as a `chr`, or character, rather than a number.

```{r, parse_incident_cost,message=FALSE, warning=FALSE}

# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost)

```

Now that incident_notional_cost is numeric, let us quickly calculate summary statistics for each animal group.

```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```

## <i> Compare the mean and the median for each animal group. what do you think this is telling us? Anything else that stands out? Any outliers? </i>

It is evident that for all animal groups the mean is larger than the median. This indicates that the notional cost distribution is positively skewed. This information is telling us that for each animal category the rescue cost most often lies in a small range which can be considered the standard rescue cost for that animal. The mean is driven upwards by some extreme large values which are outliers and may occur when there is an extreme incident requiring a lot of resources. When looking at the max values for each category we can observe that indeed there are some extremely large costs involved with some incidents which are affecting the distribution of each animal category. It is also obvious that the minimum cost is similar for all categories, almost identical, which might be pointing to a standard baseline cost incurred whenever an animal rescue is being held.

Finally, let us plot a few plots that show the distribution of incident_cost for each animal group.

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)



```

## <i> Which of these four graphs do you think best communicates the variability of the `incident_notional_cost` values? Also, can you please tell some sort of story (which animals are more expensive to rescue than others, the spread of values) and speculate about the differences in the patterns.</i>

Firstly looking at the histograms and density plots the fact that for most animal categories the notional cost is positively skewed becomes obvious, as discussed previously. This is clear from the shape of each of the graphs.

Now, the box plots provide more information as we can see the spread of values for each animal as well as the existence of outliers. It is clear that almost every category has outliers which is what we expected when we initially looked at the calculated statistics above. The box plots also show the mean median and min,max values and thus are the most informative compared to the other graphs presented above.

Looking more closely at each box plot, we observe that for the majority of animals the spread of the notional cost is small. Hence, most values are clustered in a small range, with the exception of some outliers. This indicates that within each animal category there is a similar rescue cost. This makes sense since each animal category is likely to be in the same/similar dangers and require similar techniques/hours/rescuing methods which have similar costs. It is important to note, that a few animals show a larger spread in values e.g the ferret and rabbit, which is a result of not having many observations for these animal categories (9 and 14 respectively). So there is not enough information to establish a small range of costs for these animal categories. In addition, domestic animals seem to require lower costs for rescuing compared to livestock animals such as cows, horses and deer. This might be the case because livestock animals are harder to manage as they are more wild, and live in the wild or farms rather than in homes and domestic neighbourhoods.

## Details

-   Who did you collaborate with: Nobody
-   Approximately how much time did you spend on this problem set: 6 hours
-   What, if anything, gave you the most trouble: Describing and explaining graphs in a communicative and clear manner.
